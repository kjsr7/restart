diff --git a/Makefile b/Makefile
index 0de822a..ac6bdfa 100644
--- a/Makefile
+++ b/Makefile
@@ -896,7 +896,7 @@ KBUILD_CFLAGS   += $(call cc-option,-Werror=strict-prototypes)
 # Prohibit date/time macros, which would make the build non-deterministic
 KBUILD_CFLAGS   += $(call cc-option,-Werror=date-time)
 # enforce correct pointer usage
-KBUILD_CFLAGS   += $(call cc-option,-Werror=incompatible-pointer-types)
+#KBUILD_CFLAGS   += $(call cc-option,-Werror=incompatible-pointer-types)
 
 # Require designated initializers for all marked structures
 KBUILD_CFLAGS   += $(call cc-option,-Werror=designated-init)
diff --git a/arch/x86/include/asm/cmpxchg.h b/arch/x86/include/asm/cmpxchg.h
index 56bd436..92b36aa 100644
--- a/arch/x86/include/asm/cmpxchg.h
+++ b/arch/x86/include/asm/cmpxchg.h
@@ -82,18 +82,18 @@ extern void __add_wrong_size(void)
  * store NEW in MEM.  Return the initial value in MEM.  Success is
  * indicated by comparing RETURN with OLD.
  */
-#define __raw_cmpxchg(ptr, old, new, size, lock)			\
+#define __raw_cmpxchg(ptr, old, new1, size, lock)			\
 ({									\
 	__typeof__(*(ptr)) __ret;					\
 	__typeof__(*(ptr)) __old = (old);				\
-	__typeof__(*(ptr)) __new = (new);				\
+	__typeof__(*(ptr)) __new1 = (new1);				\
 	switch (size) {							\
 	case __X86_CASE_B:						\
 	{								\
 		volatile u8 *__ptr = (volatile u8 *)(ptr);		\
 		asm volatile(lock "cmpxchgb %2,%1"			\
 			     : "=a" (__ret), "+m" (*__ptr)		\
-			     : "q" (__new), "0" (__old)			\
+			     : "q" (__new1), "0" (__old)			\
 			     : "memory");				\
 		break;							\
 	}								\
@@ -102,7 +102,7 @@ extern void __add_wrong_size(void)
 		volatile u16 *__ptr = (volatile u16 *)(ptr);		\
 		asm volatile(lock "cmpxchgw %2,%1"			\
 			     : "=a" (__ret), "+m" (*__ptr)		\
-			     : "r" (__new), "0" (__old)			\
+			     : "r" (__new1), "0" (__old)			\
 			     : "memory");				\
 		break;							\
 	}								\
@@ -111,7 +111,7 @@ extern void __add_wrong_size(void)
 		volatile u32 *__ptr = (volatile u32 *)(ptr);		\
 		asm volatile(lock "cmpxchgl %2,%1"			\
 			     : "=a" (__ret), "+m" (*__ptr)		\
-			     : "r" (__new), "0" (__old)			\
+			     : "r" (__new1), "0" (__old)			\
 			     : "memory");				\
 		break;							\
 	}								\
@@ -120,7 +120,7 @@ extern void __add_wrong_size(void)
 		volatile u64 *__ptr = (volatile u64 *)(ptr);		\
 		asm volatile(lock "cmpxchgq %2,%1"			\
 			     : "=a" (__ret), "+m" (*__ptr)		\
-			     : "r" (__new), "0" (__old)			\
+			     : "r" (__new1), "0" (__old)			\
 			     : "memory");				\
 		break;							\
 	}								\
@@ -130,14 +130,14 @@ extern void __add_wrong_size(void)
 	__ret;								\
 })
 
-#define __cmpxchg(ptr, old, new, size)					\
-	__raw_cmpxchg((ptr), (old), (new), (size), LOCK_PREFIX)
+#define __cmpxchg(ptr, old, new1, size)					\
+	__raw_cmpxchg((ptr), (old), (new1), (size), LOCK_PREFIX)
 
-#define __sync_cmpxchg(ptr, old, new, size)				\
-	__raw_cmpxchg((ptr), (old), (new), (size), "lock; ")
+#define __sync_cmpxchg(ptr, old, new1, size)				\
+	__raw_cmpxchg((ptr), (old), (new1), (size), "lock; ")
 
-#define __cmpxchg_local(ptr, old, new, size)				\
-	__raw_cmpxchg((ptr), (old), (new), (size), "")
+#define __cmpxchg_local(ptr, old, new1, size)				\
+	__raw_cmpxchg((ptr), (old), (new1), (size), "")
 
 #ifdef CONFIG_X86_32
 # include <asm/cmpxchg_32.h>
@@ -145,68 +145,68 @@ extern void __add_wrong_size(void)
 # include <asm/cmpxchg_64.h>
 #endif
 
-#define cmpxchg(ptr, old, new)						\
-	__cmpxchg(ptr, old, new, sizeof(*(ptr)))
+#define cmpxchg(ptr, old, new1)						\
+	__cmpxchg(ptr, old, new1, sizeof(*(ptr)))
 
-#define sync_cmpxchg(ptr, old, new)					\
-	__sync_cmpxchg(ptr, old, new, sizeof(*(ptr)))
+#define sync_cmpxchg(ptr, old, new1)					\
+	__sync_cmpxchg(ptr, old, new1, sizeof(*(ptr)))
 
-#define cmpxchg_local(ptr, old, new)					\
-	__cmpxchg_local(ptr, old, new, sizeof(*(ptr)))
+#define cmpxchg_local(ptr, old, new1)					\
+	__cmpxchg_local(ptr, old, new1, sizeof(*(ptr)))
 
 
-#define __raw_try_cmpxchg(_ptr, _pold, _new, size, lock)		\
+#define __raw_try_cmpxchg(_ptr, _pold, _new1, size, lock)		\
 ({									\
 	bool success;							\
 	__typeof__(_ptr) _old = (__typeof__(_ptr))(_pold);		\
 	__typeof__(*(_ptr)) __old = *_old;				\
-	__typeof__(*(_ptr)) __new = (_new);				\
+	__typeof__(*(_ptr)) __new1 = (_new1);				\
 	switch (size) {							\
 	case __X86_CASE_B:						\
 	{								\
 		volatile u8 *__ptr = (volatile u8 *)(_ptr);		\
-		asm volatile(lock "cmpxchgb %[new], %[ptr]"		\
+		asm volatile(lock "cmpxchgb %[new1], %[ptr]"		\
 			     CC_SET(z)					\
 			     : CC_OUT(z) (success),			\
 			       [ptr] "+m" (*__ptr),			\
 			       [old] "+a" (__old)			\
-			     : [new] "q" (__new)			\
+			     : [new1] "q" (__new1)			\
 			     : "memory");				\
 		break;							\
 	}								\
 	case __X86_CASE_W:						\
 	{								\
 		volatile u16 *__ptr = (volatile u16 *)(_ptr);		\
-		asm volatile(lock "cmpxchgw %[new], %[ptr]"		\
+		asm volatile(lock "cmpxchgw %[new1], %[ptr]"		\
 			     CC_SET(z)					\
 			     : CC_OUT(z) (success),			\
 			       [ptr] "+m" (*__ptr),			\
 			       [old] "+a" (__old)			\
-			     : [new] "r" (__new)			\
+			     : [new1] "r" (__new1)			\
 			     : "memory");				\
 		break;							\
 	}								\
 	case __X86_CASE_L:						\
 	{								\
 		volatile u32 *__ptr = (volatile u32 *)(_ptr);		\
-		asm volatile(lock "cmpxchgl %[new], %[ptr]"		\
+		asm volatile(lock "cmpxchgl %[new1], %[ptr]"		\
 			     CC_SET(z)					\
 			     : CC_OUT(z) (success),			\
 			       [ptr] "+m" (*__ptr),			\
 			       [old] "+a" (__old)			\
-			     : [new] "r" (__new)			\
+			     : [new1] "r" (__new1)			\
 			     : "memory");				\
 		break;							\
 	}								\
 	case __X86_CASE_Q:						\
 	{								\
 		volatile u64 *__ptr = (volatile u64 *)(_ptr);		\
-		asm volatile(lock "cmpxchgq %[new], %[ptr]"		\
+		asm volatile(lock "cmpxchgq %[new1], %[ptr]"		\
 			     CC_SET(z)					\
 			     : CC_OUT(z) (success),			\
 			       [ptr] "+m" (*__ptr),			\
 			       [old] "+a" (__old)			\
-			     : [new] "r" (__new)			\
+			     : [new1] "r" (__new1)			\
 			     : "memory");				\
 		break;							\
 	}								\
@@ -218,11 +218,11 @@ extern void __add_wrong_size(void)
 	likely(success);						\
 })
 
-#define __try_cmpxchg(ptr, pold, new, size)				\
-	__raw_try_cmpxchg((ptr), (pold), (new), (size), LOCK_PREFIX)
+#define __try_cmpxchg(ptr, pold, new1, size)				\
+	__raw_try_cmpxchg((ptr), (pold), (new1), (size), LOCK_PREFIX)
 
-#define try_cmpxchg(ptr, pold, new)					\
-	__try_cmpxchg((ptr), (pold), (new), sizeof(*(ptr)))
+#define try_cmpxchg(ptr, pold, new1)					\
+	__try_cmpxchg((ptr), (pold), (new1), sizeof(*(ptr)))
 
 /*
  * xadd() adds "inc" to "*ptr" and atomically returns the previous
@@ -236,8 +236,8 @@ extern void __add_wrong_size(void)
 #define __cmpxchg_double(pfx, p1, p2, o1, o2, n1, n2)			\
 ({									\
 	bool __ret;							\
-	__typeof__(*(p1)) __old1 = (o1), __new1 = (n1);			\
-	__typeof__(*(p2)) __old2 = (o2), __new2 = (n2);			\
+	__typeof__(*(p1)) __old1 = (o1), __new11 = (n1);			\
+	__typeof__(*(p2)) __old2 = (o2), __new12 = (n2);			\
 	BUILD_BUG_ON(sizeof(*(p1)) != sizeof(long));			\
 	BUILD_BUG_ON(sizeof(*(p2)) != sizeof(long));			\
 	VM_BUG_ON((unsigned long)(p1) % (2 * sizeof(long)));		\
@@ -246,7 +246,7 @@ extern void __add_wrong_size(void)
 		     : "=a" (__ret), "+d" (__old2),			\
 		       "+m" (*(p1)), "+m" (*(p2))			\
 		     : "i" (2 * sizeof(long)), "a" (__old1),		\
-		       "b" (__new1), "c" (__new2));			\
+		       "b" (__new11), "c" (__new12));			\
 	__ret;								\
 })
 
diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h
index 246f15b..dc93985 100644
--- a/arch/x86/include/asm/pgtable_types.h
+++ b/arch/x86/include/asm/pgtable_types.h
@@ -325,7 +325,10 @@ static inline pudval_t native_pud_val(pud_t pud)
 
 static inline pud_t native_make_pud(pudval_t val)
 {
-	return (pud_t) { .p4d.pgd = native_make_pgd(val) };
+//	return (pud_t) { .p4d.pgd = native_make_pgd(val) };
+pud_t a;
+a.p4d.pgd = native_make_pgd(val);
+return a;
 }
 
 static inline pudval_t native_pud_val(pud_t pud)
@@ -351,7 +354,10 @@ static inline pmdval_t native_pmd_val(pmd_t pmd)
 
 static inline pmd_t native_make_pmd(pmdval_t val)
 {
-	return (pmd_t) { .pud.p4d.pgd = native_make_pgd(val) };
+//	return (pmd_t) { .pud.p4d.pgd = native_make_pgd(val) };
+pmd_t a;
+a.pud.p4d.pgd = native_make_pgd(val);
+return a;
 }
 
 static inline pmdval_t native_pmd_val(pmd_t pmd)
diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h
index 533f74c..29854ba 100644
--- a/arch/x86/include/asm/string_64.h
+++ b/arch/x86/include/asm/string_64.h
@@ -136,11 +136,13 @@ DECLARE_STATIC_KEY_FALSE(mcsafe_key);
 static __always_inline __must_check int
 memcpy_mcsafe(void *dst, const void *src, size_t cnt)
 {
+/*	
 #ifdef CONFIG_X86_MCE
 	if (static_branch_unlikely(&mcsafe_key))
 		return memcpy_mcsafe_unrolled(dst, src, cnt);
 	else
 #endif
+*/
 		memcpy(dst, src, cnt);
 	return 0;
 }
diff --git a/arch/x86/kernel/vmlinux.lds.S b/arch/x86/kernel/vmlinux.lds.S
index b854ebf..a5d629b 100644
--- a/arch/x86/kernel/vmlinux.lds.S
+++ b/arch/x86/kernel/vmlinux.lds.S
@@ -372,10 +372,10 @@ SECTIONS
         DWARF_DEBUG
 
 	/* Sections to be discarded */
-	DISCARDS
+/*	DISCARDS
 	/DISCARD/ : {
 		*(.eh_frame)
-	}
+	}*/
 }
 
 
diff --git a/include/asm-generic/vmlinux.lds.h b/include/asm-generic/vmlinux.lds.h
index fcec26d..52133bd 100644
--- a/include/asm-generic/vmlinux.lds.h
+++ b/include/asm-generic/vmlinux.lds.h
@@ -547,7 +547,10 @@
 			KEEP(*(.init_array))		   \
 			VMLINUX_SYMBOL(__ctors_end) = .;
 #else
-#define KERNEL_CTORS()
+#define KERNEL_CTORS()  VMLINUX_SYMBOL(__ctors_start) = .; \
+		        KEEP(*(.ctors))			   \
+			VMLINUX_SYMBOL(__ctors_end) = .;
+
 #endif
 
 /* init and exit section handling */
diff --git a/include/linux/build_bug.h b/include/linux/build_bug.h
index 3efed0d..3ec901d 100644
--- a/include/linux/build_bug.h
+++ b/include/linux/build_bug.h
@@ -27,7 +27,12 @@
  * e.g. in a structure initializer (or where-ever else comma expressions
  * aren't permitted).
  */
+#ifdef __cplusplus
+#define BUILD_BUG_ON_ZERO(e) ((size_t) (e != -1) )
+#else
 #define BUILD_BUG_ON_ZERO(e) (sizeof(struct { int:(-!!(e)); }))
+#endif
+
 #define BUILD_BUG_ON_NULL(e) ((void *)sizeof(struct { int:(-!!(e)); }))
 
 /*
diff --git a/include/linux/compiler.h b/include/linux/compiler.h
index e8c9cd1..6a7372c 100644
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -235,7 +235,7 @@ static __always_inline void __write_once_size(volatile void *p, void *res, int s
  * required ordering.
  */
 #include <asm/barrier.h>
-
+#ifndef __cplusplus
 #define __READ_ONCE(x, check)						\
 ({									\
 	union { typeof(x) __val; char __c[1]; } __u;			\
@@ -246,6 +246,19 @@ static __always_inline void __write_once_size(volatile void *p, void *res, int s
 	smp_read_barrier_depends(); /* Enforce dependency ordering from x */ \
 	__u.__val;							\
 })
+#else
+
+#define __READ_ONCE(x, check)						\
+({									\
+	union { typeof(x) __val; char __c[1]; } __u = {0};			\
+	if (check)							\
+		__read_once_size(&(x), __u.__c, sizeof(x));		\
+	else								\
+		__read_once_size_nocheck(&(x), __u.__c, sizeof(x));	\
+	smp_read_barrier_depends(); /* Enforce dependency ordering from x */ \
+	__u.__val;							\
+})
+#endif
 #define READ_ONCE(x) __READ_ONCE(x, 1)
 
 /*
diff --git a/include/linux/compiler_types.h b/include/linux/compiler_types.h
index 6b79a9b..e3c6400 100644
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -263,7 +263,11 @@ struct ftrace_likely_data {
 
 /* Are two types/vars the same type (ignoring qualifiers)? */
 #ifndef __same_type
+#ifndef __cplusplus
 # define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
+#else
+# define __same_type(a, b) (sizeof(a) ==  sizeof(b))
+#endif
 #endif
 
 /* Is this type a native word size -- useful for atomic operations */
diff --git a/include/linux/linkage.h b/include/linux/linkage.h
index f68db9e..a60effa 100644
--- a/include/linux/linkage.h
+++ b/include/linux/linkage.h
@@ -13,7 +13,13 @@
 #endif
 
 #ifdef __cplusplus
-#define CPP_ASMLINKAGE extern "C"
+#define CPP_ASMLINKAGE 
+#ifdef __cplusplus
+extern "C" {
+#endif
+#ifdef __cplusplus
+}
+#endif
 #else
 #define CPP_ASMLINKAGE
 #endif
diff --git a/include/linux/module.h b/include/linux/module.h
index b1cc541..cb0afa7 100644
--- a/include/linux/module.h
+++ b/include/linux/module.h
@@ -124,20 +124,66 @@ extern void cleanup_module(void);
 #define console_initcall(fn)		module_init(fn)
 #define security_initcall(fn)		module_init(fn)
 
+#if defined(CONFIG_CXX_RUNTIME) && defined(__cplusplus)
+/* These are defined in lib/gcc/crtstuff.c */
+extern void begin_init(void);
+extern void end_init(void);
+extern void begin_fini(void);
+
+
+#define module_init(initfn)                                     \
+        int init_module(void)                                   \
+        {                                                       \
+                begin_init();                                   \
+                end_init();                                     \
+                return initfn();                                \
+        }
+
+#define module_exit(exitfn)                                     \
+#define module_exit(exitfn)                                     \
+        void cleanup_module(void)                               \
+        {                                                       \
+                exitfn();                                       \
+                begin_fini();                                   \
+        } 
+
+#else /* !CONFIG_CXX_RUNTIME || !__cplusplus */
+/* These macros create a dummy inline: gcc 2.9x does not count alias
+ * as usage, hence the `unused function' warning when __init functions
+ * are declared static. We use the dummy __*_module_inline functions
+ * both to kill the warning and check the type of the init/cleanup
+ * function. */
+
+/* Each module must use one module_init(), or one no_module_init */
+#define module_init(initfn)                                     \
+        static inline initcall_t __inittest(void)               \
+        { return initfn; }                                      \
+        int init_module(void) __attribute__((alias(#initfn)));
+
+/* This is only required if you want to be unloadable. */
+#define module_exit(exitfn)                                     \
+        static inline exitcall_t __exittest(void)               \
+        { return exitfn; }                                      \
+        void cleanup_module(void) __attribute__((alias(#exitfn)));
+#endif /* !CONFIG_CXX_RUNTIME || !__cplusplus */
+
+
+
 /* Each module must use one module_init(). */
-#define module_init(initfn)					\
+/*#define module_init(initfn)					\
 	static inline initcall_t __maybe_unused __inittest(void)		\
 	{ return initfn; }					\
 	int init_module(void) __attribute__((alias(#initfn)));
-
+*/
 /* This is only required if you want to be unloadable. */
-#define module_exit(exitfn)					\
+/*#define module_exit(exitfn)					\
 	static inline exitcall_t __maybe_unused __exittest(void)		\
 	{ return exitfn; }					\
 	void cleanup_module(void) __attribute__((alias(#exitfn)));
-
+*/
 #endif
 
+
 /* This means "can be init if no module support, otherwise module load
    may call it." */
 #ifdef CONFIG_MODULES
diff --git a/include/linux/rcupdate.h b/include/linux/rcupdate.h
index a6ddc42..294b567 100644
--- a/include/linux/rcupdate.h
+++ b/include/linux/rcupdate.h
@@ -337,31 +337,44 @@ static inline void rcu_preempt_sleep_check(void) { }
 #define rcu_dereference_sparse(p, space)
 #endif /* #else #ifdef __CHECKER__ */
 
+#ifdef __cplusplus
+#define TYPEOF(x) typeof(x)
+#else
+#define TYPEOF(x) typeof(*(x)) *
+#endif
+
+
 #define __rcu_access_pointer(p, space) \
-({ \
-	typeof(*p) *_________p1 = (typeof(*p) *__force)READ_ONCE(p); \
-	rcu_dereference_sparse(p, space); \
-	((typeof(*p) __force __kernel *)(_________p1)); \
-})
+        ({ \
+                TYPEOF(p) _________p1 = (TYPEOF(p)__force )ACCESS_ONCE(p); \
+                rcu_dereference_sparse(p, space); \
+                ((TYPEOF(p) __force __kernel)(_________p1)); \
+        })
+
+
 #define __rcu_dereference_check(p, c, space) \
-({ \
-	/* Dependency order vs. p above. */ \
-	typeof(*p) *________p1 = (typeof(*p) *__force)READ_ONCE(p); \
-	RCU_LOCKDEP_WARN(!(c), "suspicious rcu_dereference_check() usage"); \
-	rcu_dereference_sparse(p, space); \
-	((typeof(*p) __force __kernel *)(________p1)); \
-})
+        ({ \
+	TYPEOF(p) ________p1 = (TYPEOF(p) __force)(p); \
+        RCU_LOCKDEP_WARN(!(c), "suspicious rcu_dereference_check() usage"); \
+        rcu_dereference_sparse(p, space); \
+        ((TYPEOF(p) __force __kernel )(________p1)); \
+        })
+
+
+
 #define __rcu_dereference_protected(p, c, space) \
 ({ \
-	RCU_LOCKDEP_WARN(!(c), "suspicious rcu_dereference_protected() usage"); \
-	rcu_dereference_sparse(p, space); \
-	((typeof(*p) __force __kernel *)(p)); \
+        RCU_LOCKDEP_WARN(!(c), "suspicious rcu_dereference_protected() usage"); \
+        rcu_dereference_sparse(p, space); \
+        ((TYPEOF(p) __force __kernel )(p)); \
 })
+
+
 #define rcu_dereference_raw(p) \
 ({ \
 	/* Dependency order vs. p above. */ \
 	typeof(p) ________p1 = READ_ONCE(p); \
-	((typeof(*p) __force __kernel *)(________p1)); \
+	((TYPEOF(p) __force __kernel )(________p1)); \
 })
 
 /**
@@ -401,6 +414,7 @@ static inline void rcu_preempt_sleep_check(void) { }
  * please be careful when making changes to rcu_assign_pointer() and the
  * other macros that it invokes.
  */
+
 #define rcu_assign_pointer(p, v)					      \
 ({									      \
 	uintptr_t _r_a_p__v = (uintptr_t)(v);				      \
diff --git a/include/linux/rhashtable.h b/include/linux/rhashtable.h
index 7fd514f..0025b40 100644
--- a/include/linux/rhashtable.h
+++ b/include/linux/rhashtable.h
@@ -789,7 +789,7 @@ slow_path:
 		struct rhlist_head *list;
 
 		list = container_of(obj, struct rhlist_head, rhead);
-		RCU_INIT_POINTER(list->next, NULL);
+		rcu_assign_pointer(list->next, NULL);
 	}
 
 	rcu_assign_pointer(*pprev, obj);
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 4135469..1fc697a 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -177,7 +177,7 @@ extern long schedule_timeout_interruptible(long timeout);
 extern long schedule_timeout_killable(long timeout);
 extern long schedule_timeout_uninterruptible(long timeout);
 extern long schedule_timeout_idle(long timeout);
-asmlinkage void schedule(void);
+extern asmlinkage void schedule(void);
 extern void schedule_preempt_disabled(void);
 
 extern int __must_check io_schedule_prepare(void);
@@ -1068,6 +1068,13 @@ struct task_struct {
 	/* Number of pages to reclaim on returning to userland: */
 	unsigned int			memcg_nr_pages_over_high;
 #endif
+#ifdef CONFIG_CXX_RUNTIME
+        /* Copied from unwind-cxx.h */
+        struct {
+                void *caughtExceptions;
+                unsigned int uncaughtExceptions;
+        } cxa_eh_globals;
+#endif
 
 #ifdef CONFIG_UPROBES
 	struct uprobe_task		*utask;
diff --git a/include/linux/timer.h b/include/linux/timer.h
index e0ea1fe..cd77dd8 100644
--- a/include/linux/timer.h
+++ b/include/linux/timer.h
@@ -7,6 +7,10 @@
 #include <linux/stddef.h>
 #include <linux/debugobjects.h>
 #include <linux/stringify.h>
+#ifdef __cplusplus
+#include <linux/hrtimer.h>
+#endif
+
 
 struct tvec_base;
 
diff --git a/include/linux/types.h b/include/linux/types.h
index 34fce54..b6d6dbd 100644
--- a/include/linux/types.h
+++ b/include/linux/types.h
@@ -26,8 +26,9 @@ typedef __kernel_suseconds_t	suseconds_t;
 typedef __kernel_timer_t	timer_t;
 typedef __kernel_clockid_t	clockid_t;
 typedef __kernel_mqd_t		mqd_t;
-
+#ifndef __cplusplus
 typedef _Bool			bool;
+#endif
 
 typedef __kernel_uid32_t	uid_t;
 typedef __kernel_gid32_t	gid_t;
diff --git a/lib/cxa_atexit.c b/lib/cxa_atexit.c
new file mode 100755
index 0000000..656a420
--- /dev/null
+++ b/lib/cxa_atexit.c
@@ -0,0 +1,95 @@
+/*  cxa_atexit.c
+ *
+ *  Copyright (C) - Reykjavik University 2004
+ *  Authors:            Petur Runolfsson
+ *  E-mail:     pronto@ru.is
+ */
+
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <asm/bug.h>
+
+/*  This code is loosely based on cxa_atexit.c and cxa_finalize.c in
+ *  glibc-2.3. */
+
+/* A registered destructor function */
+struct atexit_fn {
+   void (*func) (void *);
+   void *arg;
+   void *d;
+   struct atexit_fn *next;
+};
+
+/* Linked list of registered destructors, protected by callbacks_lock */
+static struct atexit_fn *callbacks;
+//static spinlock_t callbacks_lock = SPIN_LOCK_UNLOCKED;
+static DEFINE_SPINLOCK(callbacks_lock);
+
+/* This function is called by code injected by the compiler, when constructors
+ * of static objects are run. The last argument is the __dso_handle of the
+ * module from which the call is made. */
+int
+__cxa_atexit (void (*func) (void *), void *arg, void *d)
+{
+   struct atexit_fn *afn;
+
+   /* Since the kernel never exits, static objects defined within the
+    * kernel image will dever be destroyed. Hence no need to register */
+   if (!d)
+      return 0;
+
+   afn = kmalloc(sizeof(struct atexit_fn), GFP_KERNEL);
+   if (!afn) {
+      printk(KERN_ERR "Failed to alloc atexit_fn\n");
+      return -1;
+   }
+
+   afn->func = func;
+   afn->arg = arg;
+   afn->d = d;
+
+   spin_lock_irq(&callbacks_lock);
+   afn->next = callbacks;
+   callbacks = afn;
+   spin_unlock_irq(&callbacks_lock);
+
+   return 0;
+}
+EXPORT_SYMBOL(__cxa_atexit);
+
+/* This is called from crtbeginM.o during module unloading. The argument d
+ * is the __dso_handle of the module being unloaded. This calls destructors
+ * of static objects defined in the module. */
+void
+__cxa_finalize (void *d)
+{
+   struct atexit_fn **p;
+
+   /* See comment in __cxa_atexit */
+   BUG_ON(d == NULL);
+
+   spin_lock_irq(&callbacks_lock);
+   p = &callbacks;
+   while (*p) {
+      struct atexit_fn *afn = *p;
+
+      if (afn->d == d) {
+         *p = afn->next;
+         /* Need to unlock while the destructor is called
+          * because the destructor may do funky things */
+         spin_unlock_irq(&callbacks_lock);
+
+         (afn->func)(afn->arg);
+         kfree(afn);
+
+         spin_lock_irq(&callbacks_lock);
+      } else {
+         p = &afn->next;
+      }
+   }
+   spin_unlock_irq(&callbacks_lock);
+}
+EXPORT_SYMBOL(__cxa_finalize);
diff --git a/scripts/link-vmlinux.sh b/scripts/link-vmlinux.sh
index e6818b8..86a564b 100755
--- a/scripts/link-vmlinux.sh
+++ b/scripts/link-vmlinux.sh
@@ -101,16 +101,21 @@ vmlinux_link()
 				built-in.o				\
 				--no-whole-archive			\
 				--start-group				\
+				lib/gcc/crtbegin.o                      \
 				${KBUILD_VMLINUX_LIBS}			\
 				--end-group				\
-				${1}"
+				${1}                                    \
+				lib/gcc/crtend.o"
 		else
 			objects="${KBUILD_VMLINUX_INIT}			\
+                                lib/gcc/crtbegin.o                      \
 				--start-group				\
 				${KBUILD_VMLINUX_MAIN}			\
 				${KBUILD_VMLINUX_LIBS}			\
 				--end-group				\
-				${1}"
+				${1}                                    \
+                                lib/gcc/crtend.o"
+
 		fi
 
 		${LD} ${LDFLAGS} ${LDFLAGS_vmlinux} -o ${2}		\
